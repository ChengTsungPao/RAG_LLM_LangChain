import streamlit as st
from llm_loader import load_llm
from data_loader import load_all_documents_from_folder
from rag_engine import create_qa_chain

st.set_page_config(page_title="ğŸ“ Folder RAG Chat", layout="wide")
st.title("ğŸ“ ChatGPT + å¤šæ ¼å¼è³‡æ–™å¤¾å•ç­”ç³»çµ±")

# Sidebar
openai_api_key = st.sidebar.text_input("ğŸ”‘ è«‹è¼¸å…¥ OpenAI API Key", type="password")
llm_provider = st.sidebar.selectbox("ğŸ§  é¸æ“‡ LLM æä¾›è€…", ["openai"])
llm_model = st.sidebar.selectbox("ğŸ“¦ é¸æ“‡æ¨¡å‹", ["gpt-3.5-turbo", "gpt-4-turbo"])

# ğŸ”½ ä¸»ä»‹é¢è¼¸å…¥è³‡æ–™å¤¾è·¯å¾‘ & å•é¡Œ
st.markdown("### ğŸ“‚ è«‹è¼¸å…¥ä½ æƒ³è™•ç†çš„è³‡æ–™å¤¾è·¯å¾‘")
folder_path = st.text_input("ç¯„ä¾‹ï¼š`./my_docs` æˆ– `D:/files/chatpdf/`")

if openai_api_key:
    st.success("âœ… è³‡æ–™å¤¾èˆ‡ API Key å·²å°±ç·’ï¼")
    user_question = st.text_input("ğŸ’¬ è«‹è¼¸å…¥ä½ çš„å•é¡Œ")

    if user_question:
        with st.spinner("ğŸ” æ­£åœ¨è™•ç†..."):
            docs = load_all_documents_from_folder(folder_path)
            llm = load_llm(provider=llm_provider, model_name=llm_model, api_key=openai_api_key)
            qa_chain = create_qa_chain(docs, llm, openai_api_key)
            result = qa_chain(user_question)

            st.markdown("### ğŸ§  å›ç­”å…§å®¹")
            st.write(result["result"])

            st.markdown("### ğŸ“„ å¼•ç”¨æ®µè½")
            for i, doc in enumerate(result["source_documents"]):
                with st.expander(f"ä¾†æº {i+1}: {doc.metadata['source']}"):
                    st.write(doc.page_content)
else:
    st.info("è«‹è¼¸å…¥ API é‡‘é‘°èˆ‡è³‡æ–™å¤¾è·¯å¾‘ã€‚")
